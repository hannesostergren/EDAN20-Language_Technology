{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #2: Language models\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to find n-gram statistics\n",
    "* Compute the probability of a sentence\n",
    "* Know what a language model is\n",
    "* Write a short report of 1 to 2 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have written all the missing code and run all the cells, you will submit your notebook to an automatic marking system. Do not erase the content of the cells as we will possibly check your programs manually.\n",
    "The submission instructions are at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each group will have to write Python programs to count unigrams, bigrams, and trigrams in a corpus of approximately one million words and to determine the probability of a sentence.\n",
    "* You can test you regular expression using the regex101.com site\n",
    "* Each student will have to write a short report of one to two pages and comment briefly the results. In your report, you must produce the tabulated results of your analysis as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports you may need. Add others as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import math\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import sys\n",
    "import numpy\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and analyzing a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a corpus of novels by Selma Lagerl&ouml;f from this URL:\n",
    "<a href=\"https://github.com/pnugues/ilppp/blob/master/programs/corpus/Selma.txt\">\n",
    "    <tt>https://github.com/pnugues/ilppp/blob/master/programs/corpus/Selma.txt</tt>\n",
    "</a>. The text of these novels was extracted\n",
    "from <a href=\"https://litteraturbanken.se/forfattare/LagerlofS/titlar\">Lagerlöf arkivet</a> at\n",
    "<a href=\"https://litteraturbanken.se/\">Litteraturbanken</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have to adjust the path\n",
    "corpus = open('./Selma.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch02/python\">concordance\n",
    "program </a> to print the lines containing a specific word, for instance <i>Nils</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'Nils Holgersson'\n",
    "width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces match tabs and newlines\n",
    "pattern = re.sub(' ', r'\\\\s+', pattern)\n",
    "# Replaces newlines with spaces in the text\n",
    "clean_corpus = re.sub(r'\\s+', ' ', corpus)\n",
    "concordance = ('(.{{0,{width}}}{pattern}.{{0,{width}}})'\n",
    "               .format(pattern=pattern, width=width))\n",
    "#for match in re.finditer(concordance, clean_corpus):\n",
    "    #print(match.group(1))\n",
    "# print the string with 0..width characters on either side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simple <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">tokenization\n",
    "program</a> on your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = re.findall(r'\\p{L}+', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selma',\n",
       " 'Lagerlöf',\n",
       " 'Nils',\n",
       " 'Holgerssons',\n",
       " 'underbara',\n",
       " 'resa',\n",
       " 'genom',\n",
       " 'Sverige',\n",
       " 'Första',\n",
       " 'bandet']"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(corpus)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of unique words in the original corpus and when setting all the words in lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44256\n"
     ]
    }
   ],
   "source": [
    "original = tokenize(corpus)\n",
    "unique = []\n",
    "for word in original:\n",
    "    if word not in unique:\n",
    "        unique.append(word)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercased text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41032\n"
     ]
    }
   ],
   "source": [
    "original = tokenize(corpus)\n",
    "unique = []\n",
    "lowercase = [x.lower() for x in original]\n",
    "for word in lowercase:\n",
    "    if word not in unique:\n",
    "        unique.append(word)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will write a program to tokenize your text, insert `<s>` and `</s>` tags to delimit sentences, and set all the words in lowercase letters. In the end, you will only keep the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a regular expression that matches all the characters that are neither a letter nor a punctuation sign. The punctuations signs will be the followings: `.;:?!`. In your regex, use the same order. For the definition of a letter, use a Unicode regex. You will call the regex string `nonletter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonletter = \"[^.;:?!\\p{L}]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `clean()` function that replaces all the characters that are neither a letter nor a punctuation sign with a space. The punctuations signs will be the followings: `.;:?!`.   For the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "the result will be:\n",
    "\n",
    "`En gång hade de på Mårbacka en barnpiga som hette Back Kajsa.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(paragraph):\n",
    "    cleanParagraph = re.sub(nonletter, \" \", paragraph)\n",
    "    cleanerParagraph = cleanParagraph.replace(\"  \", \" \")\n",
    "    return cleanerParagraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_para = 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa. \\\n",
    "Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, \\\n",
    "hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, \\\n",
    "när hon kammade dem, och till humöret var hon dyster och sorgbunden.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En gång hade de på Mårbacka en barnpiga som hette Back Kajsa. Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden.'"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_para = clean(test_para)\n",
    "test_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will write a sentence segmenter that will delimit each sentence with `</s>` and `<s>` symbols. For example the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "will be bracketed as:\n",
    "\n",
    "`<s> En gång hade de på Mårbacka en barnpiga som hette Back-Kajsa </s>`\n",
    "\n",
    "As algorithm, you will use a simple heuristics to detect the sentence boundaries: A sentence starts with a capital letter and ends with a period-equivalent punctuation sign. You will write a regex to match these boundaries with a regular expression and you will insert `</s>\\n<s>` symbols with a substitution function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentence boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a regular expression that matches a punctuation, a sequence of spaces, and an uppercase letter. Call this regex string `sentence_boundaries`. In the regex, you will remember the value of the uppercase letter using a backreference. Use the Unicode regexes for the letters and the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_boundaries = r\"[.;:?!]+\\s+(\\p{Lu})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacement markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a string to replace the matched boundaries with the sentence boundary markup. Remember that a sentence ends with `</s>` and starts with `<s>` and that there is one sentence per line. Hint: The markup is `</s>\\n<s>`. Remember also that the first letter of your sentence is in a regex backreference. Call the regex string `sentence_markup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_markup = r\" </s>\\n<s> \\1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your regexes to segment your text. Use the string `sentence_boundaries`, `sentence_markup`, and `test_para` as input and `text` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(sentence_boundaries, sentence_markup, test_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert markup codes in the beginning and end of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<s> \" + text + \" </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden. </s>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the space duplicates with one space and remove the punctuation signs. For the spaces, use the Unicode regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(\"\\s+\", \" \", text)\n",
    "text = re.sub(\"\\.\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s> <s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden </s>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `segment_sentences(text)` function to gather the code in the Segmenter section and set the text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(text):\n",
    "    text = re.sub(sentence_boundaries, sentence_markup, text)\n",
    "    text = re.sub(\"\\.\", \"\", text)\n",
    "    text = \"<s> \" + text + \" </s>\"\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> en gång hade de på mårbacka en barnpiga som hette back kajsa </s> <s> hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden </s>\n"
     ]
    }
   ],
   "source": [
    "print(segment_sentences(test_para))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate roughly the accuracy of your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and segment the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = segment_sentences(clean(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be a normalized text without punctuation signs where all the sentences are delimited with `<s>` and `</s>` tags. The five last lines of the text should look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> hon hade fått större kärlek av sina föräldrar än någon annan han visste och sådan kärlek måste vändas i välsignelse </s> <s> då prästen sade detta kom alla människor att se bort mot klara gulla och de förundrade sig över vad de såg </s> <s> prästens ord tycktes redan ha gått i uppfyllelse </s> <s> där stod klara fina gulleborg ifrån skrolycka hon som var uppkallad efter själva solen vid sina föräldrars grav och lyste som en förklarad </s> <s> hon var likaså vacker som den söndagen då hon gick till kyrkan i den röda klänningen om inte vackrare </s>\n"
     ]
    }
   ],
   "source": [
    "print(corpus[-557:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create a list of words from your string. You will consider that a space or a carriage return is an item separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = corpus.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five last lines of the corpus should like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'hon', 'hade', 'fått', 'större', 'kärlek', 'av', 'sina', 'föräldrar', 'än', 'någon', 'annan', 'han', 'visste', 'och', 'sådan', 'kärlek', 'måste', 'vändas', 'i', 'välsignelse', '</s>', '<s>', 'då', 'prästen', 'sade', 'detta', 'kom', 'alla', 'människor', 'att', 'se', 'bort', 'mot', 'klara', 'gulla', 'och', 'de', 'förundrade', 'sig', 'över', 'vad', 'de', 'såg', '</s>', '<s>', 'prästens', 'ord', 'tycktes', 'redan', 'ha', 'gått', 'i', 'uppfyllelse', '</s>', '<s>', 'där', 'stod', 'klara', 'fina', 'gulleborg', 'ifrån', 'skrolycka', 'hon', 'som', 'var', 'uppkallad', 'efter', 'själva', 'solen', 'vid', 'sina', 'föräldrars', 'grav', 'och', 'lyste', 'som', 'en', 'förklarad', '</s>', '<s>', 'hon', 'var', 'likaså', 'vacker', 'som', 'den', 'söndagen', 'då', 'hon', 'gick', 'till', 'kyrkan', 'i', 'den', 'röda', 'klänningen', 'om', 'inte', 'vackrare', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(words[-101:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unigrams and bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and try programs to compute the frequency of unigrams and bigrams of the training set: [<a\n",
    "            href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams(words):\n",
    "    frequency = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in frequency:\n",
    "            frequency[words[i]] += 1\n",
    "        else:\n",
    "            frequency[words[i]] = 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 59047),\n",
       " ('selma', 51),\n",
       " ('lagerlöf', 269),\n",
       " ('nils', 87),\n",
       " ('holgerssons', 6),\n",
       " ('underbara', 23),\n",
       " ('resa', 316),\n",
       " ('genom', 688),\n",
       " ('sverige', 54),\n",
       " ('</s>', 59047),\n",
       " ('första', 525),\n",
       " ('bandet', 6),\n",
       " ('bokutgåva', 11),\n",
       " ('albert', 15),\n",
       " ('bonniers', 11),\n",
       " ('förlag', 11),\n",
       " ('stockholm', 77),\n",
       " ('den', 11611),\n",
       " ('kristliga', 2),\n",
       " ('dagvisan', 2)]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = unigrams(words)\n",
    "list(frequency.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams.append((words[i], words[i + 1]))\n",
    "    frequency_bigrams = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        if bigrams[i] in frequency_bigrams:\n",
    "            frequency_bigrams[bigrams[i]] += 1\n",
    "        else:\n",
    "            frequency_bigrams[bigrams[i]] = 1\n",
    "    return frequency_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'selma'), 8),\n",
       " (('selma', 'lagerlöf'), 11),\n",
       " (('lagerlöf', 'nils'), 1),\n",
       " (('nils', 'holgerssons'), 6),\n",
       " (('holgerssons', 'underbara'), 4),\n",
       " (('underbara', 'resa'), 4),\n",
       " (('resa', 'genom'), 6),\n",
       " (('genom', 'sverige'), 5),\n",
       " (('sverige', '</s>'), 17),\n",
       " (('</s>', '<s>'), 59046),\n",
       " (('<s>', 'första'), 11),\n",
       " (('första', 'bandet'), 1),\n",
       " (('bandet', 'bokutgåva'), 2),\n",
       " (('bokutgåva', 'albert'), 11),\n",
       " (('albert', 'bonniers'), 11),\n",
       " (('bonniers', 'förlag'), 11),\n",
       " (('förlag', 'stockholm'), 10),\n",
       " (('stockholm', '</s>'), 24),\n",
       " (('<s>', 'den'), 1375),\n",
       " (('den', 'kristliga'), 2)]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_bigrams = bigrams(words)\n",
    "list(frequency_bigrams.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bigrams = bigrams(words)\n",
    "test_bigrams[('<s>', 'selma')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the report, tell what is the possible number of bigrams and their real number? Explain why such a difference. What would be the possible number of 4-grams.\n",
    "\n",
    "Propose a solution to cope with bigrams unseen in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the likelihood of a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to compute a sentence's probability using unigrams. You may find useful the dictionaries that we saw in the mutual information program: [<a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]. Your function will return the perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function should print and tabulate the results as in the examples below with the sentence _Det var en gång en katt som hette Nils_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t C(wi) \t #words \t P(wi)\n",
    "=====================================================\n",
    "det \t 21108 \t 1041631 \t 0.0202643738521607\n",
    "var \t 12090 \t 1041631 \t 0.01160679741674355\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "gång \t 1332 \t 1041631 \t 0.001278763784871994\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "katt \t 16 \t 1041631 \t 1.5360525944408337e-05\n",
    "som \t 16288 \t 1041631 \t 0.015637015411407686\n",
    "hette \t 97 \t 1041631 \t 9.312318853797554e-05\n",
    "nils \t 87 \t 1041631 \t 8.352285982272032e-05\n",
    "</s> \t 59047 \t 1041631 \t 0.056687060964967444\n",
    "=====================================================\n",
    "Prob. unigrams:\t 5.361459667285409e-27\n",
    "Geometric mean prob.: 0.0023600885848765307\n",
    "Entropy rate:\t 8.726943273141258\n",
    "Perplexity:\t 423.71290908655254\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_lm(freq, words):\n",
    "    lenCorpus = len(corpus.split())\n",
    "    Cwi = []\n",
    "    for word in words:\n",
    "        Cwi.append(unigrams(corpus.split())[word])\n",
    "    print(\"======================================================\")\n",
    "    print(\"wi      C(wi)         #words          P(wi)\")\n",
    "    print(\"======================================================\")\n",
    "    for i in range(0, len(Cwi)):\n",
    "        print(words[i] + \"\\t\" + str(Cwi[i]) + \"\\t\\t\" + str(lenCorpus) + \"\\t\\t\" + str(Cwi[i]/lenCorpus))\n",
    "    print(\"======================================================\")\n",
    "    probList = [Cwi[i]/lenCorpus for i in range(0, len(words))]\n",
    "    mul = numpy.prod(probList)\n",
    "    print(mul)\n",
    "    pk = [prob * math.log(prob) for prob in probList]\n",
    "    S = -sum(pk)\n",
    "    print(\"Prob. unigrams:   \" + str(mul))\n",
    "    print(\"Geometric mean prob.: \" + str(pow(mul, 1/len(words))))\n",
    "    print(\"Entropy rate:    \" + str(S))\n",
    "    perplexity = pow(1/mul, 1/len(words))\n",
    "    print(\"Perplexity:      \" + str(perplexity))\n",
    "    return perplexity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en', 'gång', 'en', 'katt', 'som', 'hette', 'nils', '</s>']"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'det var en gång en katt som hette nils </s>'\n",
    "sent_words = sentence.split()\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "det\t21076\t\t1041564\t\t0.020234954357101435\n",
      "var\t12089\t\t1041564\t\t0.011606583944913611\n",
      "en\t13505\t\t1041564\t\t0.012966077936641436\n",
      "gång\t1328\t\t1041564\t\t0.0012750056645582989\n",
      "en\t13505\t\t1041564\t\t0.012966077936641436\n",
      "katt\t16\t\t1041564\t\t1.536151403082288e-05\n",
      "som\t16288\t\t1041564\t\t0.01563802128337769\n",
      "hette\t97\t\t1041564\t\t9.31291788118637e-05\n",
      "nils\t87\t\t1041564\t\t8.35282325425994e-05\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "5.333137479311845e-27\n",
      "Prob. unigrams:   5.333137479311845e-27\n",
      "Geometric mean prob.: 0.0023588388822626993\n",
      "Entropy rate:    0.2090612424307462\n",
      "Perplexity:      423.93739034891485\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams = unigram_lm(frequency, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_unigrams = int(perplexity_unigrams)\n",
    "perplexity_unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to compute the sentence probability using bigrams. Your function will tabulate and print the results as below. It will return the perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t wi+1 \t Ci,i+1 \t C(i) \t P(wi+1|wi)\n",
    "=====================================================\n",
    "<s>\t det \t 5672 \t 59047 \t 0.09605907158704083\n",
    "det \t var \t 3839 \t 21108 \t 0.1818741709304529\n",
    "var \t en \t 712 \t 12090 \t 0.058891645988420185\n",
    "en \t gång \t 706 \t 13514 \t 0.052242119283705785\n",
    "gång \t en \t 20 \t 1332 \t 0.015015015015015015\n",
    "en \t katt \t 6 \t 13514 \t 0.0004439840165754033\n",
    "katt \t som \t 2 \t 16 \t 0.125\n",
    "som \t hette \t 45 \t 16288 \t 0.002762770137524558\n",
    "hette \t nils \t 0 \t 97 \t 0.0 \t *backoff: \t 8.352285982272032e-05\n",
    "nils \t </s> \t 2 \t 87 \t 0.022988505747126436\n",
    "=====================================================\n",
    "Prob. bigrams:\t 2.376007803503683e-19\n",
    "Geometric mean prob.: 0.013727289294133601\n",
    "Entropy rate:\t 6.186809422848149\n",
    "Perplexity:\t 72.84759420254609\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_lm(dic, bigDic, text):\n",
    "    prevWord=\"<s>\"\n",
    "    unigramPredict = 1 #dic[prevWord]/sum(dic.values())\n",
    "    entropyRate = 0\n",
    "    bigrams = list(frequency_bigrams.keys())\n",
    "    print('=====================================================')\n",
    "    print('wi','\\t' ,'wi+1', '\\t', 'Ci,i+1',' ', 'C(i)', '\\t','P(wi+1|wi)')\n",
    "    print('=====================================================')\n",
    "   \n",
    "    for index in range(len(text)):\n",
    "        word = text[index]\n",
    "        #prob = dic[word]/sum(dic.values())\n",
    "        ci1 = bigDic.get((prevWord,word))\n",
    "        if bigDic.get((prevWord,word)) == None:\n",
    "            ci1 = 0\n",
    "            totalProb = dic.get(word)/(sum(dic.values()))\n",
    "        else:   \n",
    "            totalProb = ci1/dic.get(prevWord)\n",
    "  \n",
    "        unigramPredict *= totalProb\n",
    "        entropyRate += math.log(totalProb,2)\n",
    "        print(prevWord, '\\t',word , '\\t',ci1, '\\t', dic.get(prevWord), '\\t', totalProb ) \n",
    "        prevWord = word\n",
    "    print('=====================================================')\n",
    "    print('Prob. unigrams:',unigramPredict)\n",
    "    print('Geometric mean prob.:', unigramPredict ** (1./len(text)))\n",
    "    print('Entropy rate:', -entropyRate/len(text))\n",
    "    print('Perplexity: ', 2 ** ( -entropyRate/len(text)))\n",
    "    return  math.floor(2 ** ( -entropyRate/len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t det \t 5672 \t 59047 \t 0.09605907158704083\n",
      "det \t var \t 3839 \t 21076 \t 0.18215031315240082\n",
      "var \t en \t 712 \t 12089 \t 0.05889651749524361\n",
      "en \t gång \t 702 \t 13505 \t 0.05198074787115883\n",
      "gång \t en \t 20 \t 1328 \t 0.015060240963855422\n",
      "en \t katt \t 6 \t 13505 \t 0.00044427989633469083\n",
      "katt \t som \t 2 \t 16 \t 0.125\n",
      "som \t hette \t 45 \t 16288 \t 0.002762770137524558\n",
      "hette \t nils \t 0 \t 97 \t 8.35282325425994e-05\n",
      "nils \t </s> \t 2 \t 87 \t 0.022988505747126436\n",
      "=====================================================\n",
      "Prob. unigrams: 2.3767736839150797e-19\n",
      "Geometric mean prob.: 0.013727731714283164\n",
      "Entropy rate: 6.186762926627613\n",
      "Perplexity:  72.84524645535865\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams = bigram_lm(frequency, frequency_bigrams, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_bigrams = int(perplexity_bigrams)\n",
    "perplexity_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this sentence, _Det var en gång en katt som hette Nils_, write three other sentences that will form your test set and run your programs on them. You will insert them in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigrams: \n",
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "han\t21580\t\t1041564\t\t0.020718842049072355\n",
      "stod\t1192\t\t1041564\t\t0.0011444327952963044\n",
      "i\t16508\t\t1041564\t\t0.015849242101301505\n",
      "predikstolen\t22\t\t1041564\t\t2.1122081792381457e-05\n",
      "och\t36356\t\t1041564\t\t0.03490520025653728\n",
      "väntade\t223\t\t1041564\t\t0.00021410110180459385\n",
      "medan\t568\t\t1041564\t\t0.0005453337480942122\n",
      "sista\t276\t\t1041564\t\t0.00026498611703169465\n",
      "versen\t4\t\t1041564\t\t3.84037850770572e-06\n",
      "av\t5433\t\t1041564\t\t0.005216194108091293\n",
      "predikstolspsalmen\t1\t\t1041564\t\t9.6009462692643e-07\n",
      "sjöngs\t3\t\t1041564\t\t2.8802838807792895e-06\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "2.692058607844137e-44\n",
      "Prob. unigrams:   2.692058607844137e-44\n",
      "Geometric mean prob.: 0.0004451107049951685\n",
      "Entropy rate:    0.46941361756050537\n",
      "Perplexity:      2246.6321047274173\n",
      "\n",
      "Bigrams:\n",
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t han \t 5058 \t 59047 \t 0.08566057547377513\n",
      "han \t stod \t 132 \t 21580 \t 0.0061167747914735865\n",
      "stod \t i \t 56 \t 1192 \t 0.04697986577181208\n",
      "i \t predikstolen \t 5 \t 16508 \t 0.0003028834504482675\n",
      "predikstolen \t och \t 4 \t 22 \t 0.18181818181818182\n",
      "och \t väntade \t 85 \t 36356 \t 0.002337990978105402\n",
      "väntade \t medan \t 2 \t 223 \t 0.008968609865470852\n",
      "medan \t sista \t 1 \t 568 \t 0.0017605633802816902\n",
      "sista \t versen \t 1 \t 276 \t 0.0036231884057971015\n",
      "versen \t av \t 1 \t 4 \t 0.25\n",
      "av \t predikstolspsalmen \t 1 \t 5433 \t 0.00018406037180195104\n",
      "predikstolspsalmen \t sjöngs \t 1 \t 1 \t 1.0\n",
      "sjöngs \t </s> \t 1 \t 3 \t 0.3333333333333333\n",
      "=====================================================\n",
      "Prob. unigrams: 2.781107008498649e-24\n",
      "Geometric mean prob.: 0.01541759901074525\n",
      "Entropy rate: 6.01927807854214\n",
      "Perplexity:  64.86094231034627\n",
      "\n",
      "Unigrams: \n",
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "prästen\t260\t\t1041564\t\t0.0002496246030008718\n",
      "skulle\t5433\t\t1041564\t\t0.005216194108091293\n",
      "ha\t2128\t\t1041564\t\t0.002043081366099443\n",
      "velat\t292\t\t1041564\t\t0.0002803476310625175\n",
      "störta\t38\t\t1041564\t\t3.6483595823204335e-05\n",
      "ner\t1417\t\t1041564\t\t0.0013604540863547511\n",
      "på\t14228\t\t1041564\t\t0.013660226351909244\n",
      "sina\t1278\t\t1041564\t\t0.0012270009332119773\n",
      "knän\t3\t\t1041564\t\t2.8802838807792895e-06\n",
      "och\t36356\t\t1041564\t\t0.03490520025653728\n",
      "be\t107\t\t1041564\t\t0.00010273012508112799\n",
      "dem\t3182\t\t1041564\t\t0.0030550211028798997\n",
      "om\t8067\t\t1041564\t\t0.007745083355415509\n",
      "förbarmande\t10\t\t1041564\t\t9.600946269264299e-06\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "8.252726834768753e-47\n",
      "Prob. unigrams:   8.252726834768753e-47\n",
      "Geometric mean prob.: 0.0008467850163449988\n",
      "Entropy rate:    0.45690784630907655\n",
      "Perplexity:      1180.9372871479554\n",
      "\n",
      "Bigrams:\n",
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t prästen \t 47 \t 59047 \t 0.0007959760868460718\n",
      "prästen \t skulle \t 7 \t 260 \t 0.026923076923076925\n",
      "skulle \t ha \t 430 \t 5433 \t 0.07914595987483895\n",
      "ha \t velat \t 37 \t 2128 \t 0.01738721804511278\n",
      "velat \t störta \t 1 \t 292 \t 0.003424657534246575\n",
      "störta \t ner \t 7 \t 38 \t 0.18421052631578946\n",
      "ner \t på \t 218 \t 1417 \t 0.15384615384615385\n",
      "på \t sina \t 84 \t 14228 \t 0.005903851560303626\n",
      "sina \t knän \t 3 \t 1278 \t 0.002347417840375587\n",
      "knän \t och \t 2 \t 3 \t 0.6666666666666666\n",
      "och \t be \t 17 \t 36356 \t 0.00046759819562108043\n",
      "be \t dem \t 7 \t 107 \t 0.06542056074766354\n",
      "dem \t om \t 55 \t 3182 \t 0.017284726587052168\n",
      "om \t förbarmande \t 2 \t 8067 \t 0.00024792363951902817\n",
      "förbarmande \t </s> \t 4 \t 10 \t 0.4\n",
      "=====================================================\n",
      "Prob. unigrams: 1.3866405732039065e-27\n",
      "Geometric mean prob.: 0.01619810687963527\n",
      "Entropy rate: 5.948030978822676\n",
      "Perplexity:  61.73560944070748\n",
      "\n",
      "Unigrams: \n",
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "medan\t568\t\t1041564\t\t0.0005453337480942122\n",
      "han\t21580\t\t1041564\t\t0.020718842049072355\n",
      "läste\t118\t\t1041564\t\t0.00011329116597731872\n",
      "upp\t2448\t\t1041564\t\t0.0023503116467159003\n",
      "inledningen\t3\t\t1041564\t\t2.8802838807792895e-06\n",
      "sköljde\t4\t\t1041564\t\t3.84037850770572e-06\n",
      "blodvåg\t2\t\t1041564\t\t1.92018925385286e-06\n",
      "efter\t1823\t\t1041564\t\t0.0017502525048868818\n",
      "blodvåg\t2\t\t1041564\t\t1.92018925385286e-06\n",
      "upp\t2448\t\t1041564\t\t0.0023503116467159003\n",
      "i\t16508\t\t1041564\t\t0.015849242101301505\n",
      "hans\t2219\t\t1041564\t\t0.002130449977149748\n",
      "ansikte\t292\t\t1041564\t\t0.0002803476310625175\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "2.7087037970137823e-49\n",
      "Prob. unigrams:   2.7087037970137823e-49\n",
      "Geometric mean prob.: 0.0003395561000641737\n",
      "Entropy rate:    0.368945863181002\n",
      "Perplexity:      2945.021455397229\n",
      "\n",
      "Bigrams:\n",
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t medan \t 152 \t 59047 \t 0.0025742205361830406\n",
      "medan \t han \t 136 \t 568 \t 0.23943661971830985\n",
      "han \t läste \t 17 \t 21580 \t 0.0007877664504170528\n",
      "läste \t upp \t 14 \t 118 \t 0.11864406779661017\n",
      "upp \t inledningen \t 2 \t 2448 \t 0.0008169934640522876\n",
      "inledningen \t sköljde \t 1 \t 3 \t 0.3333333333333333\n",
      "sköljde \t blodvåg \t 1 \t 4 \t 0.25\n",
      "blodvåg \t efter \t 1 \t 2 \t 0.5\n",
      "efter \t blodvåg \t 1 \t 1823 \t 0.0005485463521667581\n",
      "blodvåg \t upp \t 1 \t 2 \t 0.5\n",
      "upp \t i \t 205 \t 2448 \t 0.08374183006535947\n",
      "i \t hans \t 207 \t 16508 \t 0.012539374848558275\n",
      "hans \t ansikte \t 55 \t 2219 \t 0.024785939612438034\n",
      "ansikte \t </s> \t 68 \t 292 \t 0.2328767123287671\n",
      "=====================================================\n",
      "Prob. unigrams: 3.2600201933739267e-21\n",
      "Geometric mean prob.: 0.034407933655985753\n",
      "Entropy rate: 4.861114935124253\n",
      "Perplexity:  29.063064640792103\n",
      "\n",
      "Unigrams: \n",
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "det\t21076\t\t1041564\t\t0.020234954357101435\n",
      "var\t12089\t\t1041564\t\t0.011606583944913611\n",
      "vreden\t10\t\t1041564\t\t9.600946269264299e-06\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "1.2782993310619646e-10\n",
      "Prob. unigrams:   1.2782993310619646e-10\n",
      "Geometric mean prob.: 0.003362467848908132\n",
      "Entropy rate:    0.29346581202034183\n",
      "Perplexity:      297.4006131611704\n",
      "\n",
      "Bigrams:\n",
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t det \t 5672 \t 59047 \t 0.09605907158704083\n",
      "det \t var \t 3839 \t 21076 \t 0.18215031315240082\n",
      "var \t vreden \t 1 \t 12089 \t 8.271982794275788e-05\n",
      "vreden \t </s> \t 2 \t 10 \t 0.2\n",
      "=====================================================\n",
      "Prob. unigrams: 2.8947290877174916e-07\n",
      "Geometric mean prob.: 0.023195406144696642\n",
      "Entropy rate: 5.430017082202632\n",
      "Perplexity:  43.111984923300774\n",
      "\n",
      "Unigrams: \n",
      "======================================================\n",
      "wi      C(wi)         #words          P(wi)\n",
      "======================================================\n",
      "han\t21580\t\t1041564\t\t0.020718842049072355\n",
      "hade\t13197\t\t1041564\t\t0.012670368791548096\n",
      "läst\t45\t\t1041564\t\t4.320425821168934e-05\n",
      "upp\t2448\t\t1041564\t\t0.0023503116467159003\n",
      "inledningen\t3\t\t1041564\t\t2.8802838807792895e-06\n",
      "och\t36356\t\t1041564\t\t0.03490520025653728\n",
      "han\t21580\t\t1041564\t\t0.020718842049072355\n",
      "böjde\t88\t\t1041564\t\t8.448832716952583e-05\n",
      "sig\t9242\t\t1041564\t\t0.008873194542054064\n",
      "ner\t1417\t\t1041564\t\t0.0013604540863547511\n",
      "för\t9435\t\t1041564\t\t0.009058492805050866\n",
      "att\t28020\t\t1041564\t\t0.026901851446478563\n",
      "läsa\t168\t\t1041564\t\t0.00016129589732364022\n",
      "fader\t25\t\t1041564\t\t2.4002365673160746e-05\n",
      "vår\t317\t\t1041564\t\t0.00030434999673567824\n",
      "</s>\t59047\t\t1041564\t\t0.05669070743612491\n",
      "======================================================\n",
      "9.218471417963086e-46\n",
      "Prob. unigrams:   9.218471417963086e-46\n",
      "Geometric mean prob.: 0.0015321143564733849\n",
      "Entropy rate:    0.7062116388309514\n",
      "Perplexity:      652.6927939646727\n",
      "\n",
      "Bigrams:\n",
      "=====================================================\n",
      "wi \t wi+1 \t Ci,i+1   C(i) \t P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t han \t 5058 \t 59047 \t 0.08566057547377513\n",
      "han \t hade \t 2044 \t 21580 \t 0.09471733086190917\n",
      "hade \t läst \t 18 \t 13197 \t 0.00136394635144351\n",
      "läst \t upp \t 4 \t 45 \t 0.08888888888888889\n",
      "upp \t inledningen \t 2 \t 2448 \t 0.0008169934640522876\n",
      "inledningen \t och \t 1 \t 3 \t 0.3333333333333333\n",
      "och \t han \t 734 \t 36356 \t 0.020189239740345474\n",
      "han \t böjde \t 16 \t 21580 \t 0.0007414272474513438\n",
      "böjde \t sig \t 51 \t 88 \t 0.5795454545454546\n",
      "sig \t ner \t 195 \t 9242 \t 0.021099329149534732\n",
      "ner \t för \t 23 \t 1417 \t 0.016231474947071278\n",
      "för \t att \t 2932 \t 9435 \t 0.3107578166401696\n",
      "att \t läsa \t 54 \t 28020 \t 0.0019271948608137045\n",
      "läsa \t fader \t 2 \t 168 \t 0.011904761904761904\n",
      "fader \t vår \t 3 \t 25 \t 0.12\n",
      "vår \t </s> \t 11 \t 317 \t 0.03470031545741325\n",
      "=====================================================\n",
      "Prob. unigrams: 2.3628614120227875e-26\n",
      "Geometric mean prob.: 0.025023029655943697\n",
      "Entropy rate: 5.320599715818792\n",
      "Perplexity:  39.96318646261407\n"
     ]
    }
   ],
   "source": [
    "test_set = 'Han stod i predikstolen och väntade, medan sista versen av predikstolspsalmen sjöngs. Prästen skulle ha velat störta ner på sina knän och be dem om förbarmande. Medan han läste upp inledningen, sköljde blodvåg efter blodvåg upp i hans ansikte. Det var vreden. Han hade läst upp inledningen, och han böjde sig ner för att läsa Fader vår.'\n",
    "test_sentences = segment_sentences(clean(test_set)).split()\n",
    "sent = \"\"\n",
    "sentenceArr = []\n",
    "for word in test_sentences:\n",
    "    if word == '</s>':\n",
    "        sent += word\n",
    "        sentenceArr.append(sent)\n",
    "        sent = \"\"\n",
    "    elif word != '<s>':\n",
    "        sent += word + \" \"\n",
    "for sentence in sentenceArr:\n",
    "    sentence = sentence.split()\n",
    "    print(\"\\nUnigrams: \")\n",
    "    unigram_lm(frequency, sentence)\n",
    "    print(\"\\nBigrams:\")\n",
    "    bigram_lm(frequency, frequency_bigrams, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online prediction of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now carry out an online prediction of words. You will consider two cases:\n",
    "1. Prediction of the current word a user is typing;\n",
    "2. Prediction of the next word.\n",
    "\n",
    "Ideally, you would write a loop that reads the words and apply the models while typing. As the Jupyter labs are not designed for interactive input and output, we will simplify the experimental settings with constant strings at a given time of the input.  \n",
    "\n",
    "We will assume the user is typing the phrase: _Det var en gång_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a more accurate prediction, you will use a trigram counting function. Program this function following the model of your bigram counting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(words):\n",
    "    trigrams = [tuple(words[inx:inx + 3]) for inx in range(len(words) - 2)]\n",
    "    frequencies = {}\n",
    "    for trigram in trigrams:\n",
    "        if trigram in frequencies:\n",
    "            frequencies[trigram] += 1\n",
    "        else:\n",
    "            frequencies[trigram] = 1\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_trigrams = trigrams(words)\n",
    "frequency_trigrams[('det', 'var', 'en')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user starts typing _Det var en gång_. After the 2nd character, your program tries to help the user with suggested words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_text = 'De'.lower()\n",
    "starting_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to rank the five first candidates at this point. Assign these predictions in a list that you will call `current_word_predictions_1`. Note that you are starting a sentence and you can then use the bigram frequencies. Write a sorting key that will enable you have a deterministic ranking of the words or bigrams with identical frequencies: When two words have the same frequency, you will sort them by alphabetic order. You can do this with a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_nbr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {}\n",
    "for key in frequency_bigrams.keys():\n",
    "    if key[0] == '<s>' and key[1].startswith(starting_text):\n",
    "        candidates[key] = frequency_bigrams[key]\n",
    "        \n",
    "sortedCandidates = dict(sorted(candidates.items(), key=lambda x: x[0][1].lower()))\n",
    "p = sorted(sortedCandidates, key=sortedCandidates.get, reverse=True)[:cand_nbr]\n",
    "current_word_predictions_1 = [i[1] for i in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'de', 'den', 'detta', 'denna']"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now suppose that the user has typed: _Det var en_. After detecting a space, your program starts predicting a next possible word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det var en '"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_text = \"Det var en \".lower()\n",
    "current_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize this text and return a list of tokens. Call it `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en']"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to propose the five next possible words ranked by frequency using a trigram model. Assign these predictions to a variable that you will call `next_word_predictions`. Write a sorting key that will enable you have a deterministic ranking of the words or bigrams with identical frequencies: When two words have the same frequency, you will sort them by alphabetic order. You can do this with a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = {}\n",
    "for key in frequency_trigrams.keys():\n",
    "    if key[0] == 'var' and key[1] == 'en':\n",
    "        candidates[key] = frequency_trigrams[key]\n",
    "        \n",
    "sortedCandidates = dict(sorted(candidates.items(), key=lambda x: x[0][2].lower()))\n",
    "p = sorted(sortedCandidates, key=sortedCandidates.get, reverse=True)[:cand_nbr]\n",
    "next_word_predictions = [i[2] for i in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stor', 'liten', 'gammal', 'god', 'sådan']"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us suppose that the user has typed _Det var en g_, rank the five possible candidates. Assign these predictions in a list that you will call `current_word_predictions_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_text = \"Det var en g\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gammal', 'god', 'gång', 'ganska', 'glädje']\n"
     ]
    }
   ],
   "source": [
    "candidates = {}\n",
    "for key in frequency_trigrams.keys():\n",
    "    if key[0] == 'var' and key[1] == 'en' and key[2].startswith('g'):\n",
    "        candidates[key] = frequency_trigrams[key]\n",
    "        \n",
    "sortedCandidates = dict(sorted(candidates.items(), key=lambda x: x[0][2].lower()))\n",
    "p = sorted(sortedCandidates, key=sortedCandidates.get, reverse=True)[:cand_nbr]\n",
    "current_word_predictions_2 = [i[2] for i in p]\n",
    "print(current_word_predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gammal', 'god', 'gång', 'ganska', 'glädje']"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checked answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic marking system will check these answers: `(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423,\n",
       " 48,\n",
       " ['det', 'de', 'den', 'detta', 'denna'],\n",
       " ['stor', 'liten', 'gammal', 'god', 'sådan'],\n",
       " ['gammal', 'god', 'gång', 'ganska', 'glädje'])"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"ha6882os-s\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"2-language_models.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of the perplexities and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"perplexity_unigrams\": 423, \"perplexity_bigrams\": 72, \"current_word_predictions_1\": [\"det\", \"de\", \"den\", \"detta\", \"denna\"], \"next_word_predictions\": [\"stor\", \"liten\", \"gammal\", \"god\", \"s\\\\u00e5dan\"], \"current_word_predictions_2\": [\"gammal\", \"god\", \"g\\\\u00e5ng\", \"ganska\", \"gl\\\\u00e4dje\"]}'"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ANSWER = json.dumps({'perplexity_unigrams': perplexity_unigrams,\n",
    "                     'perplexity_bigrams': perplexity_bigrams,\n",
    "                     'current_word_predictions_1': current_word_predictions_1,\n",
    "                     'next_word_predictions': next_word_predictions,\n",
    "                     'current_word_predictions_2': current_word_predictions_2})\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The checking script will accept perplexities with a margin, like for instance:\n",
    "```\n",
    "(421, 72, ['det', 'de', 'den', 'detta', 'denna'], ['stor', 'liten', 'gammal', 'god', 'sådan'], ['gammal', 'god', 'gång', 'ganska', 'glädje'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSIGNMENT = 2\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'correct',\n",
       " 'signature': 'ed18ad2de12ee002efb60c2154aec19a8a2a7fcd8b86090e96bb982d8f7bd4cd08dd35d7ea8c845e00eb5362c951028230d10fdaa06d23b957525fddb513ad77',\n",
       " 'submission_id': '4bdbd646-880f-4536-b2c8-5a1f15613baf'}"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": STIL_ID,\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "                   verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will include the regular expression you use to segment the text and the unigram and bigram tables for three sentences and _Det var en gång en katt som hette Nils_.\n",
    "2. Execute the Jupyter notebook by Peter Norvig here: <a href=\"http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\">https://nbviewer.jupyter.org/url/norvig.com/ipython/How to Do Things with Words.ipynb</a>. Just run all the cells and be sure that you understand the code. You will find the data here: <a href=\"http://norvig.com/ngrams/\">http://norvig.com/ngrams/</a>.\n",
    "3. In your report, after the description of your program, you will describe one experiment with Norvig's notebook and a long string of words your will create yourself or copy from a text you like. You will remove all the punctuation and white spaces from this string. You will set this string in lowercase letters. You will just add a cell at the end of Sect. 7 in Norvig's notebook, where you will use your string and run the notebook cell with the <tt>segment()</tt> and <tt>segment2()</tt> functions. You will comment the segmentation results you obtain with the unigram and bigram models.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is September 23, 2022. You will have only three submission attempts. The deadline for the second and third ones are one week after you are noticed of your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
